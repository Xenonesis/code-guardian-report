import { SecurityIssue } from '@/hooks/useAnalysis';
import { calculateSecurityScore } from '../security/securityAnalysisEngine';

export class MetricsCalculator {
  public calculateQualityScore(issues: SecurityIssue[], linesAnalyzed: number): number {
    const criticalIssues = issues.filter(i => i.severity === 'Critical').length;
    const highIssues = issues.filter(i => i.severity === 'High').length;
    const mediumIssues = issues.filter(i => i.severity === 'Medium').length;
    const lowIssues = issues.filter(i => i.severity === 'Low').length;

    // Enhanced weighted scoring system with exponential penalties for critical issues
    const criticalWeight = criticalIssues * 15; // Increased from 10
    const highWeight = highIssues * 8; // Increased from 5
    const mediumWeight = mediumIssues * 3; // Increased from 2
    const lowWeight = lowIssues * 1;
    
    // Additional complexity penalties
    const complexityPenalty = this.calculateComplexityPenalty(issues);
    const diversityPenalty = this.calculateIssueDiversityPenalty(issues);
    const totalWeightedIssues = criticalWeight + highWeight + mediumWeight + lowWeight + complexityPenalty + diversityPenalty;

    // Enhanced density calculation with logarithmic scaling
    const baseDensity = linesAnalyzed > 0 ? (totalWeightedIssues / linesAnalyzed) * 1000 : 0;
    const logDensity = baseDensity > 0 ? Math.log10(baseDensity + 1) * 20 : 0;
    
    // Quality score with multiple factors
    let qualityScore = Math.max(0, Math.min(100, 100 - logDensity));
    
    // Apply additional modifiers
    qualityScore = this.applyQualityModifiers(qualityScore, issues, linesAnalyzed);

    if (issues.length === 0) {
      qualityScore = 100;
    } else if (qualityScore < 5) {
      qualityScore = 5; // Minimum floor
    }

    return Math.round(qualityScore);
  }

  private calculateComplexityPenalty(issues: SecurityIssue[]): number {
    // Penalty for having multiple issue types in the same file
    const fileIssueMap = new Map<string, Set<string>>();
    issues.forEach(issue => {
      if (!fileIssueMap.has(issue.filename)) {
        fileIssueMap.set(issue.filename, new Set());
      }
      fileIssueMap.get(issue.filename)!.add(issue.type);
    });

    let complexityPenalty = 0;
    fileIssueMap.forEach((issueTypes, _) => {
      if (issueTypes.size > 3) {
        complexityPenalty += (issueTypes.size - 3) * 2; // Penalty for complex files
      }
    });

    return complexityPenalty;
  }

  private calculateIssueDiversityPenalty(issues: SecurityIssue[]): number {
    // Penalty for having many different types of security issues
    const uniqueTypes = new Set(issues.map(issue => issue.type));
    const diversityPenalty = uniqueTypes.size > 5 ? (uniqueTypes.size - 5) * 1.5 : 0;
    return diversityPenalty;
  }

  private applyQualityModifiers(baseScore: number, issues: SecurityIssue[], linesAnalyzed: number): number {
    let modifiedScore = baseScore;

    // Bonus for larger codebases with fewer issues (better engineering practices)
    if (linesAnalyzed > 1000 && issues.length < 5) {
      modifiedScore += 5;
    }

    // Penalty for small codebases with many issues (poor practices)
    if (linesAnalyzed < 500 && issues.length > 10) {
      modifiedScore -= 10;
    }

    // Bonus for having only low-severity issues
    const hasOnlyLowSeverity = issues.every(issue => issue.severity === 'Low');
    if (hasOnlyLowSeverity && issues.length > 0) {
      modifiedScore += 3;
    }

    // Additional penalty for secret detection issues
    const secretIssues = issues.filter(issue => issue.category === 'Secret Detection' || issue.type === 'Secret');
    if (secretIssues.length > 0) {
      const criticalSecrets = secretIssues.filter(s => s.severity === 'Critical').length;
      const highSecrets = secretIssues.filter(s => s.severity === 'High').length;

      // Heavy penalty for exposed secrets
      modifiedScore -= (criticalSecrets * 8) + (highSecrets * 5) + (secretIssues.length * 2);
    }

    return Math.max(0, Math.min(100, modifiedScore));
  }

  public calculateVulnerabilityDensity(issues: SecurityIssue[], linesAnalyzed: number): number {
    const vulnerabilityDensity = (issues.length / linesAnalyzed) * 1000;
    return Math.round(vulnerabilityDensity * 100) / 100;
  }

  public calculateSummaryMetrics(issues: SecurityIssue[], linesAnalyzed: number) {
    const criticalIssues = issues.filter(i => i.severity === 'Critical').length;
    const highIssues = issues.filter(i => i.severity === 'High').length;
    const mediumIssues = issues.filter(i => i.severity === 'Medium').length;
    const lowIssues = issues.filter(i => i.severity === 'Low').length;

    // Calculate coverage based on analysis quality (fewer issues = better coverage)
    const totalIssues = issues.length;
    const severityWeightedIssues = (criticalIssues * 4) + (highIssues * 3) + (mediumIssues * 2) + (lowIssues * 1);
    const coveragePercentage = totalIssues === 0 ? 100 : 
      Math.max(40, Math.min(95, 100 - (severityWeightedIssues * 2)));
    
    // Calculate risk level based on severity distribution
    const riskLevel = this.calculateTechnicalRisk(issues, linesAnalyzed);
    
    return {
      criticalIssues,
      highIssues,
      mediumIssues,
      lowIssues,
      securityScore: calculateSecurityScore(issues),
      qualityScore: this.calculateQualityScore(issues, linesAnalyzed),
      coveragePercentage: Math.round(coveragePercentage),
      linesAnalyzed,
      riskLevel
    };
  }

  public calculateDetailedMetrics(issues: SecurityIssue[], linesAnalyzed: number) {
    const criticalIssues = issues.filter(issue => issue.severity === 'Critical').length;
    const highIssues = issues.filter(issue => issue.severity === 'High').length;
    const mediumIssues = issues.filter(issue => issue.severity === 'Medium').length;
    const lowIssues = issues.filter(issue => issue.severity === 'Low').length;
    
    // Enhanced technical debt calculation with complexity factors
    const criticalDebt = criticalIssues * 12; // Increased from 8
    const highDebt = highIssues * 6; // Increased from 4
    const mediumDebt = mediumIssues * 3; // Increased from 2
    const lowDebt = lowIssues * 1;
    
    // Add complexity debt based on issue distribution
    const complexityDebt = this.calculateComplexityDebt(issues);
    const totalDebtHours = criticalDebt + highDebt + mediumDebt + lowDebt + complexityDebt;
    
    // Enhanced maintainability index with multiple factors
    const maintainabilityIndex = this.calculateMaintainabilityIndex(issues, linesAnalyzed);
    
    // Advanced duplication estimation based on issue patterns
    const duplicatedLines = this.estimateDuplicatedLines(issues, linesAnalyzed);
    
    // Sophisticated test coverage calculation
    const testCoverage = this.calculateTestCoverage(issues, linesAnalyzed);
    
    // New advanced metrics
    const codeComplexity = this.calculateCodeComplexity(issues, linesAnalyzed);
    const securityMaturity = this.calculateSecurityMaturity(issues);
    const technicalRisk = this.calculateTechnicalRisk(issues, linesAnalyzed);
    
    return {
      vulnerabilityDensity: this.calculateVulnerabilityDensity(issues, linesAnalyzed),
      technicalDebt: totalDebtHours > 0 ? `${totalDebtHours} hours` : '0 hours',
      maintainabilityIndex: Math.round(maintainabilityIndex),
      duplicatedLines,
      testCoverage,
      codeComplexity: Math.round(codeComplexity),
      securityMaturity: Math.round(securityMaturity),
      technicalRisk: technicalRisk,
      qualityGrade: this.calculateQualityGrade(issues, linesAnalyzed),
      performanceScore: this.calculatePerformanceScore(issues),
      architectureScore: this.calculateArchitectureScore(issues, linesAnalyzed)
    };
  }

  private calculateComplexityDebt(issues: SecurityIssue[]): number {
    // Calculate additional debt based on issue complexity patterns
    const fileComplexityMap = new Map<string, number>();
    issues.forEach(issue => {
      const current = fileComplexityMap.get(issue.filename) || 0;
      fileComplexityMap.set(issue.filename, current + 1);
    });

    let complexityDebt = 0;
    fileComplexityMap.forEach(issueCount => {
      if (issueCount > 5) {
        complexityDebt += (issueCount - 5) * 0.5; // Additional debt for complex files
      }
    });

    return complexityDebt;
  }

  private calculateMaintainabilityIndex(issues: SecurityIssue[], linesAnalyzed: number): number {
    const issuesDensity = linesAnalyzed > 0 ? (issues.length / linesAnalyzed) * 1000 : 0;
    const severityImpact = this.calculateSeverityImpact(issues);
    const fileDistribution = this.calculateFileDistribution(issues);
    
    // Complex maintainability calculation
    const baseMaintainability = Math.max(0, 100 - (issuesDensity * 8));
    const severityPenalty = severityImpact * 5;
    const distributionBonus = fileDistribution > 0.7 ? -5 : 0; // Penalty for concentrated issues
    
    return Math.max(0, Math.min(100, baseMaintainability - severityPenalty + distributionBonus));
  }

  private calculateSeverityImpact(issues: SecurityIssue[]): number {
    const total = issues.length;
    if (total === 0) return 0;
    
    const criticalRatio = issues.filter(i => i.severity === 'Critical').length / total;
    const highRatio = issues.filter(i => i.severity === 'High').length / total;
    
    return (criticalRatio * 2) + (highRatio * 1.5);
  }

  private calculateFileDistribution(issues: SecurityIssue[]): number {
    const fileMap = new Map<string, number>();
    issues.forEach(issue => {
      fileMap.set(issue.filename, (fileMap.get(issue.filename) || 0) + 1);
    });
    
    const totalFiles = fileMap.size;
    const maxIssuesPerFile = Math.max(...Array.from(fileMap.values()));
    
    return totalFiles > 0 ? maxIssuesPerFile / issues.length : 0;
  }

  private estimateDuplicatedLines(issues: SecurityIssue[], linesAnalyzed: number): number {
    // More sophisticated duplication estimation
    const patternMap = new Map<string, number>();
    issues.forEach(issue => {
      const pattern = issue.type + ':' + issue.severity;
      patternMap.set(pattern, (patternMap.get(pattern) || 0) + 1);
    });

    let duplicationFactor = 0.03; // Base 3%
    patternMap.forEach(count => {
      if (count > 3) {
        duplicationFactor += 0.01; // Increase for repeated patterns
      }
    });

    return Math.floor(linesAnalyzed * Math.min(duplicationFactor, 0.15)); // Cap at 15%
  }

  private calculateTestCoverage(issues: SecurityIssue[], linesAnalyzed: number): number {
    const testRelatedIssues = issues.filter(issue => 
      issue.filename.toLowerCase().includes('test') || 
      issue.filename.toLowerCase().includes('spec') ||
      issue.message.toLowerCase().includes('test') ||
      issue.filename.toLowerCase().includes('.test.') ||
      issue.filename.toLowerCase().includes('.spec.')
    ).length;
    
    const hasTestFiles = testRelatedIssues > 0;
    const issueRatio = issues.length > 0 ? issues.length / linesAnalyzed * 1000 : 0;
    
    let baseCoverage = hasTestFiles ? 75 : 35;
    
    // Adjust based on code quality indicators
    if (issueRatio < 1) baseCoverage += 15; // Low issue density suggests good testing
    else if (issueRatio > 5) baseCoverage -= 20; // High issue density suggests poor testing
    
    return Math.max(20, Math.min(95, baseCoverage));
  }

  private calculateCodeComplexity(issues: SecurityIssue[], linesAnalyzed: number): number {
    const complexityIndicators = issues.filter(issue =>
      issue.message.toLowerCase().includes('complex') ||
      issue.message.toLowerCase().includes('nested') ||
      issue.type.includes('SQL') ||
      issue.type.includes('XSS') ||
      issue.type.includes('Injection')
    ).length;

    const baseComplexity = linesAnalyzed > 0 ? (complexityIndicators / linesAnalyzed) * 10000 : 0;
    return Math.min(100, baseComplexity);
  }

  private calculateSecurityMaturity(issues: SecurityIssue[]): number {
    const criticalIssues = issues.filter(i => i.severity === 'Critical').length;
    const totalIssues = issues.length;

    if (totalIssues === 0) return 95;

    // Additional penalty for secret detection issues
    const secretIssues = issues.filter(issue => issue.category === 'Secret Detection' || issue.type === 'Secret');
    const secretPenalty = secretIssues.length * 5; // Secrets indicate poor security practices

    const criticalRatio = criticalIssues / totalIssues;
    const maturityScore = 100 - (criticalRatio * 60) - ((totalIssues / 10) * 5) - secretPenalty;

    return Math.max(10, Math.min(100, maturityScore));
  }

  private calculateTechnicalRisk(issues: SecurityIssue[], linesAnalyzed: number): string {
    const criticalCount = issues.filter(i => i.severity === 'Critical').length;
    const highCount = issues.filter(i => i.severity === 'High').length;
    const issueRatio = linesAnalyzed > 0 ? issues.length / linesAnalyzed * 1000 : 0;

    // Check for secret detection issues which increase risk significantly
    const secretIssues = issues.filter(issue => issue.category === 'Secret Detection' || issue.type === 'Secret');
    const criticalSecrets = secretIssues.filter(s => s.severity === 'Critical').length;
    const highSecrets = secretIssues.filter(s => s.severity === 'High').length;

    // Any critical secrets automatically elevate risk
    if (criticalSecrets > 0) return 'Very High';
    if (highSecrets > 2 || secretIssues.length > 5) return 'Very High';
    if (secretIssues.length > 0) return 'High';

    if (criticalCount > 5 || issueRatio > 20) return 'Very High';
    if (criticalCount > 2 || highCount > 10 || issueRatio > 10) return 'High';
    if (criticalCount > 0 || highCount > 5 || issueRatio > 5) return 'Medium';
    if (issues.length > 0) return 'Low';
    return 'Very Low';
  }

  private calculateQualityGrade(issues: SecurityIssue[], linesAnalyzed: number): string {
    const qualityScore = this.calculateQualityScore(issues, linesAnalyzed);
    
    if (qualityScore >= 90) return 'A+';
    if (qualityScore >= 85) return 'A';
    if (qualityScore >= 80) return 'A-';
    if (qualityScore >= 75) return 'B+';
    if (qualityScore >= 70) return 'B';
    if (qualityScore >= 65) return 'B-';
    if (qualityScore >= 60) return 'C+';
    if (qualityScore >= 55) return 'C';
    if (qualityScore >= 50) return 'C-';
    if (qualityScore >= 40) return 'D';
    return 'F';
  }

  private calculatePerformanceScore(issues: SecurityIssue[]): number {
    const performanceRelatedIssues = issues.filter(issue =>
      issue.message.toLowerCase().includes('performance') ||
      issue.message.toLowerCase().includes('slow') ||
      issue.message.toLowerCase().includes('inefficient') ||
      issue.type.includes('SQL') ||
      issue.message.toLowerCase().includes('loop') ||
      issue.message.toLowerCase().includes('memory')
    ).length;

    const totalIssues = issues.length;
    if (totalIssues === 0) return 90;

    const performanceRatio = performanceRelatedIssues / totalIssues;
    const performanceScore = 100 - (performanceRatio * 50) - (performanceRelatedIssues * 5);
    
    return Math.max(20, Math.min(100, performanceScore));
  }

  private calculateArchitectureScore(issues: SecurityIssue[], linesAnalyzed: number): number {
    const architecturalIssues = issues.filter(issue =>
      issue.message.toLowerCase().includes('coupling') ||
      issue.message.toLowerCase().includes('dependency') ||
      issue.message.toLowerCase().includes('structure') ||
      issue.type.includes('Hardcoded') ||
      issue.message.toLowerCase().includes('configuration')
    ).length;

    const fileDistribution = this.calculateFileDistribution(issues);
    const issueConcentration = fileDistribution > 0.8 ? 15 : 0; // Penalty for concentrated issues
    
    // Factor in codebase size for architecture complexity
    const codebaseComplexity = linesAnalyzed > 5000 ? 5 : 0; // Penalty for large codebases
    
    const baseScore = 85;
    const architecturalPenalty = architecturalIssues * 3;
    const concentrationPenalty = issueConcentration;
    
    return Math.max(20, Math.min(100, baseScore - architecturalPenalty - concentrationPenalty - codebaseComplexity));
  }

  public analyzeDependencies(packageJsonContent?: string) {
    // Parse real package.json if provided
    if (!packageJsonContent) {
      return {
        total: 0,
        production: 0,
        development: 0,
        vulnerable: 0,
        outdated: 0,
        licenses: [] as string[]
      };
    }

    try {
      const packageData = JSON.parse(packageJsonContent);
      const prodDeps = packageData.dependencies || {};
      const devDeps = packageData.devDependencies || {};
      
      const productionCount = Object.keys(prodDeps).length;
      const developmentCount = Object.keys(devDeps).length;
      const totalCount = productionCount + developmentCount;

      // Extract licenses if available
      const licenses = packageData.license ? [packageData.license] : [];

      // Note: Vulnerability scanning requires external API calls
      // For now, return counts based on actual dependencies found
      return {
        total: totalCount,
        production: productionCount,
        development: developmentCount,
        vulnerable: 0, // Real vulnerability scanning would require npm audit API
        outdated: 0,   // Real version checking would require npm registry API
        licenses
      };
    } catch {
      // Invalid JSON parse, return empty
      return {
        total: 0,
        production: 0,
        development: 0,
        vulnerable: 0,
        outdated: 0,
        licenses: [] as string[]
      };
    }
  }
}